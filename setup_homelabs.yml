- name: "Inventory Sanity Check"
  hosts: all
  gather_facts: false
  run_once: true
  vars_files:
    - vars/paths.yml
  tasks:
    - name: "Check: project_dir is defined"
      assert:
        that: 
          - project_dir is defined
          - project_dir != ""
        fail_msg: "ERROR: project_dir is missing for {{ inventory_hostname }}. Check hosts.ini."

    - name: "Check: project_dir exists in storage_map"
      assert:
        that:
          - project_dir in storage_map
        fail_msg: "ERROR: '{{ project_dir }}' not found in vars/paths.yml. Spelling error?"

    - name: "Check: trusted_network syntax (no trailing dashes)"
      assert:
        that:
          - "'-' not in trusted_network"
        fail_msg: "ERROR: trusted_network for {{ inventory_hostname }} has a trailing dash or typo: '{{ trusted_network }}'"

    - name: "Check: nfs_allowed_ips is formatted correctly"
      assert:
        that:
          - nfs_allowed_ips is search('^([0-9]{1,3}\.){3}[0-9]{1,3}')
        fail_msg: "ERROR: nfs_allowed_ips looks malformed. It should be a space-separated string of IPs."

- name: Proxmox Global Configuration
  hosts: all
  remote_user: ubuntu# Use the user created via Cloud-Init
  become: true # Use sudo for system tasks (Docker, etc.)
  vars_files:
    - vars.yml
  tasks:
    - name: Debug user variables
      debug:
        msg:
          - "Current ansible_user_id: {{ ansible_user_id }}"
          - "SSH User ansible_user: {{ ansible_user }}"
          - "sudo Home: {{ ansible_env.HOME }}"
    # 1. THE SYSTEM STUFF (Requires sudo)

    - name: Force resize of sda1
      become: true
      shell: |
        # This grows the partition first
        growpart /dev/sda 1 || true
        # This stretches the filesystem
        resize2fs /dev/sda1
      register: resize_res

    - name: Verify new size
      debug:
        msg: "Root partition is now: {{ ansible_facts['mounts'] | selectattr('mount', 'equalto', '/') | map(attribute='size_total') | first | human_readable }}"

    - name: Wait for cloud-init to finish
      ansible.builtin.command: cloud-init status --wait
      register: cloud_init_result
      # Allow rc 0 (success) or rc 2 (already done)
      failed_when: cloud_init_result.rc not in [0, 2]
      changed_when: false

    - name: Setup QEMU Guest Agent
      include_tasks:
        file: tasks/qemu_agent.yml
        apply:
          tags: vm

    - name: Apply the packages and apt tags to the include and to all tasks in packages.yml
      include_tasks:
        file: tasks/packages.yml
        apply:
          tags: packages
      tags:
        - packages
        - apt

    - name: Install docker
      include_tasks:
        file: tasks/docker_install.yml
        apply:
          tags: docker
      tags: [docker]

    - name: Setup Dotfiles
      include_tasks:
        file: tasks/dotfiles.yml
        apply:
          become: false
          tags: dotfiles
      tags: dotfiles

    - name: docker compose pull
      include_tasks:
        file: tasks/docker_services_pull.yml
        apply:
          become: false
          tags: compose
      tags: docker

  handlers:
    - name: Restart SSH
      service:
        name: ssh
        state: restarted

- name: Provision Network Infrastructure
  hosts: network_servers
  remote_user: ubuntu# Use the user created via Cloud-Init
  become: true # Use sudo for system tasks (Docker, etc.)
  vars_files:
    - vars.yml
  tasks:
    - name: Prepare System DNS (Fix Port 53)
      include_tasks: tasks/dns_prep.yml

    - name: Setup Tailscale
      include_tasks: tasks/tailscale.yml

    - name: Ensure Pi-hole configuration directory exists
      file:
        path: "{{ DOCKER_CONFIG_PATH }}/pihole/etc-dnsmasq.d"
        state: directory
        owner: ubuntu
        group: users
        mode: '0755'
        recurse: yes  # Ensures the parent 'pihole' folder is also set correctly
      tags: dns

    - name: Create local DNS mappings for Pi-hole
      template:
        src: templates/05-lan.conf.j2
        dest: "{{ DOCKER_CONFIG_PATH }}/pihole/etc-dnsmasq.d/05-lan.conf"
      notify: Restart Pi-hole

    - name: docker compose up
      include_tasks:
        file: tasks/docker_services_up.yml
        apply:
          become: false
          tags: compose
      tags: docker

  handlers:
    - name: Restart Pi-hole
      shell:
        cmd: "docker compose restart pihole"
        chdir: "{{ user_home }}/github_repo/dotfiles/docker_compose/{{ project_dir}}/net/"

# PLAY 2: Only the NAS servers get this
- name: NAS Specific Configuration
  hosts: nas_servers
  remote_user: ubuntu# Use the user created via Cloud-Init
  become: true # Use sudo for system tasks (Docker, etc.)
  vars_files:
    - vars/paths.yml
  tasks:
    - name: Install Cockpit
      include_tasks:
        file: tasks/cockpit.yml
        apply:
          tags: cockpit
      tags: [cockpit]

    - name: Setup NFS
      include_tasks: tasks/nfs_server_nas.yml
      ignore_errors: yes
  handlers:
    - name: Reload NFS
      command: exportfs -ra
      become: true

# PLAY 3: Only the Media servers get this
- name: Media Specific Configuration
  hosts: media_servers
  remote_user: ubuntu
  become: true # Use sudo for system tasks (Docker, etc.)
  vars_files:
    - vars/paths.yml
    - vars.yml
  tasks:
    - name: Configure Docker DNS from PiHole on Media
      template:
        src: templates/docker_daemon.json.j2
        dest: /etc/docker/daemon.json
      notify: Restart Docker

    # - name: Install Homebrew
    #   include_tasks:
    #     file: tasks/homebrew.yml
    #     apply:
    #       tags: brew_install
    #   tags: brew_install
    #
    # - name: Install Homebrew Packages
    #   include_tasks:
    #     file: tasks/homebrew_packages.yml
    #     apply:
    #       tags: brew
    #   tags: [brew, packages]
    #
    #

    # - name: Install zerobrew Packages
    #   include_tasks:
    #     file: tasks/zerobrew.yml
    #     apply:
    #       tags: brew
    #   tags: [brew, packages]
    #
    - name: Setup lazyvim
      include_tasks:
        file: tasks/lazyvim.yml
        apply:
          become: false
          tags: lazyvim
      tags: dotfiles

    - name: Setup NFS Client Mounts
      include_tasks: tasks/nfs_client_media.yml

    - name: docker compose up
      include_tasks:
        file: tasks/docker_services_up.yml
        apply:
          become: false
          tags: compose
      tags: docker


    # - name: Apply the miniforge tag to the include and to all tasks in miniforge.yml
    #   include_tasks:
    #     file: tasks/miniforge.yml
    #     apply:
    #       tags: miniforge
    #   tags: miniforge
    #
  handlers:
    - name: Restart Docker
      service:
        name: docker
        state: restarted
